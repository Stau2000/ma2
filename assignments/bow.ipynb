{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part I: Bag-of-Words Model\n",
    "\n",
    "Please see the description of the assignment in the README file (section 1) <br>\n",
    "**Guide notebook**: [guides/bow_guide.ipynb](guides/bow_guide.ipynb)\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "* Note that you should report results using a classification report. \n",
    "\n",
    "* Also, remember to include some reflections on your results: Are there any hyperparameters that are particularly important?\n",
    "\n",
    "<br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "Implementet gridsearch to tune the mode. increased accuracy by 1%-2% from 76%-77% to 78%\n",
    "\n",
    "implemented tfidf and increased the accuracy with 2% to 80%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "We can load this data directly from [Hugging Face Datasets](https://huggingface.co/docs/datasets/) - The HuggingFace Hub- into a Pandas DataFrame. Pretty neat!\n",
    "\n",
    "**Note**: This cell will download the dataset and keep it in memory. If you run this cell multiple times, it will download the dataset multiple times.\n",
    "\n",
    "You are welcome to increase the `frac` parameter to load more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "train = pd.read_parquet(f\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])\n",
    "test = pd.read_parquet(f\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label mapping\n",
    "label_map = {\n",
    "    0: 'World',\n",
    "    1: 'Sports',\n",
    "    2: 'Business',\n",
    "    3: 'Sci/Tech'\n",
    "}\n",
    "\n",
    "# Function to preprocess the dataset\n",
    "def preprocess(df: pd.DataFrame, frac: float = 0.01, label_map: dict = label_map, seed: int = 42):\n",
    "    return (\n",
    "        df\n",
    "        .assign(label=lambda x: x['label'].map(label_map))\n",
    "        [lambda df: df['label'].isin(label_map.values())]\n",
    "        .groupby('label')[['text', 'label']]\n",
    "        .apply(lambda x: x.sample(frac=frac, random_state=seed))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "# Preprocess data\n",
    "train_df = preprocess(train, frac=0.01)\n",
    "test_df = preprocess(test, frac=0.1)\n",
    "\n",
    "# Clear up memory\n",
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_df[\"text\"], train_df[\"label\"], test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the BoW mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit TF-IDF on the training set only\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_df=0.95, min_df=5)\n",
    "X_train_vectorized = tfidf.fit_transform(X_train)  # Fit only on train set\n",
    "\n",
    "# Transform validation and test sets using the same vectorizer\n",
    "X_val_vectorized = tfidf.transform(X_val)  # Transform only\n",
    "test_vectorized = tfidf.transform(test_df[\"text\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.15501908, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.0s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.1s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.1s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=   0.3s\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time=   0.2s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=   0.3s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   0.1s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=   0.2s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=   0.2s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=   0.0s\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time=   0.1s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time=   0.3s\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time=   0.3s\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time=   0.2s\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time=   0.3s\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time=   0.3s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=   3.9s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=   3.1s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=   3.6s\n",
      "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time=   7.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time=   7.6s\n",
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time=   7.7s\n",
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time=   7.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aiml25-ma2/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time=   7.8s\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time=   3.2s\n",
      "Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define GridSearchCV parameters for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2'],  # Regularization type\n",
    "    'solver': ['liblinear', 'saga']  # Compatible solvers\n",
    "}\n",
    "\n",
    "# Initialize logistic regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "grid_search = GridSearchCV(lr, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Get the best model from GridSearch\n",
    "best_lr_clf = grid_search.best_estimator_\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_vectorized = tfidf.transform(X_val) # note that we use transform here, not fit_transform\n",
    "\n",
    "y_pred = best_lr_clf.predict(X_val_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate BoW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.83      0.61      0.70        62\n",
      "      Sports       0.73      0.67      0.70        60\n",
      "    Business       0.74      0.88      0.80        60\n",
      "    Sci/Tech       0.75      0.86      0.80        58\n",
      "\n",
      "    accuracy                           0.75       240\n",
      "   macro avg       0.76      0.76      0.75       240\n",
      "weighted avg       0.76      0.75      0.75       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Evaluate on Validation Set\n",
    "y_pred = best_lr_clf.predict(X_val_vectorized)\n",
    "print(\"\\nPerformance on Validation Set:\")\n",
    "print(classification_report(y_val, y_pred, target_names=label_map.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.77      0.73      0.75       190\n",
      "      Sports       0.77      0.75      0.76       190\n",
      "    Business       0.84      0.89      0.86       190\n",
      "    Sci/Tech       0.81      0.83      0.82       190\n",
      "\n",
      "    accuracy                           0.80       760\n",
      "   macro avg       0.80      0.80      0.80       760\n",
      "weighted avg       0.80      0.80      0.80       760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Evaluate on Test Set\n",
    "y_test_pred = best_lr_clf.predict(test_vectorized)\n",
    "print(\"\\nPerformance on Test Set:\")\n",
    "print(classification_report(test_df[\"label\"], y_test_pred, target_names=label_map.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-ma2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
